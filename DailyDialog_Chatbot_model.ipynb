{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4619727,"sourceType":"datasetVersion","datasetId":2688897}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nimport numpy as np\nimport pandas as pd\nimport ast\nimport re\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:07:11.606175Z","iopub.execute_input":"2025-05-14T06:07:11.606433Z","iopub.status.idle":"2025-05-14T06:07:18.371444Z","shell.execute_reply.started":"2025-05-14T06:07:11.606412Z","shell.execute_reply":"2025-05-14T06:07:18.370742Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove*.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:07:18.372528Z","iopub.execute_input":"2025-05-14T06:07:18.372971Z","iopub.status.idle":"2025-05-14T06:10:17.344172Z","shell.execute_reply.started":"2025-05-14T06:07:18.372946Z","shell.execute_reply":"2025-05-14T06:10:17.343006Z"}},"outputs":[{"name":"stdout","text":"--2025-05-14 06:07:18--  http://nlp.stanford.edu/data/glove.6B.zip\nResolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://nlp.stanford.edu/data/glove.6B.zip [following]\n--2025-05-14 06:07:18--  https://nlp.stanford.edu/data/glove.6B.zip\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n--2025-05-14 06:07:18--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\nResolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\nConnecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 862182613 (822M) [application/zip]\nSaving to: ‘glove.6B.zip’\n\nglove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n\n2025-05-14 06:09:57 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n\nArchive:  glove.6B.zip\n  inflating: glove.6B.50d.txt        \n  inflating: glove.6B.100d.txt       \n  inflating: glove.6B.200d.txt       \n  inflating: glove.6B.300d.txt       \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"shutil.copytree(\"/kaggle/input/dailydialog-unlock-the-conversation-potential-in\",\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in\",dirs_exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:17.345596Z","iopub.execute_input":"2025-05-14T06:10:17.345924Z","iopub.status.idle":"2025-05-14T06:10:17.600047Z","shell.execute_reply.started":"2025-05-14T06:10:17.345895Z","shell.execute_reply":"2025-05-14T06:10:17.599110Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/dailydialog-unlock-the-conversation-potential-in'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in/train.csv\")\nvalidation_df = pd.read_csv(\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in/validation.csv\")\ntest_df = pd.read_csv(\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:17.602482Z","iopub.execute_input":"2025-05-14T06:10:17.602833Z","iopub.status.idle":"2025-05-14T06:10:17.724312Z","shell.execute_reply.started":"2025-05-14T06:10:17.602803Z","shell.execute_reply":"2025-05-14T06:10:17.723266Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:17.725383Z","iopub.execute_input":"2025-05-14T06:10:17.725691Z","iopub.status.idle":"2025-05-14T06:10:17.747756Z","shell.execute_reply.started":"2025-05-14T06:10:17.725666Z","shell.execute_reply":"2025-05-14T06:10:17.747039Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                              dialog                    act  \\\n0  ['Say , Jim , how about going for a few beers ...  [3 4 2 2 2 3 4 1 3 4]   \n1  ['Can you do push-ups ? '\\n \" Of course I can ...          [2 1 2 2 1 1]   \n2  ['Can you study with the radio on ? '\\n ' No ,...            [2 1 2 1 1]   \n3  ['Are you all right ? '\\n ' I will be all righ...              [2 1 1 1]   \n4  ['Hey John , nice skates . Are they new ? '\\n ...    [2 1 2 1 1 2 1 3 4]   \n\n                 emotion  \n0  [0 0 0 0 0 0 4 4 4 4]  \n1          [0 0 6 0 0 0]  \n2            [0 0 0 0 0]  \n3              [0 0 0 0]  \n4    [0 0 0 0 0 6 0 6 0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialog</th>\n      <th>act</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['Say , Jim , how about going for a few beers ...</td>\n      <td>[3 4 2 2 2 3 4 1 3 4]</td>\n      <td>[0 0 0 0 0 0 4 4 4 4]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['Can you do push-ups ? '\\n \" Of course I can ...</td>\n      <td>[2 1 2 2 1 1]</td>\n      <td>[0 0 6 0 0 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['Can you study with the radio on ? '\\n ' No ,...</td>\n      <td>[2 1 2 1 1]</td>\n      <td>[0 0 0 0 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['Are you all right ? '\\n ' I will be all righ...</td>\n      <td>[2 1 1 1]</td>\n      <td>[0 0 0 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['Hey John , nice skates . Are they new ? '\\n ...</td>\n      <td>[2 1 2 1 1 2 1 3 4]</td>\n      <td>[0 0 0 0 0 6 0 6 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_df[\"dialog\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:17.748695Z","iopub.execute_input":"2025-05-14T06:10:17.749009Z","iopub.status.idle":"2025-05-14T06:10:17.755900Z","shell.execute_reply.started":"2025-05-14T06:10:17.748982Z","shell.execute_reply":"2025-05-14T06:10:17.755197Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'[\\'Say , Jim , how about going for a few beers after dinner ? \\'\\n \\' You know that is tempting but is really not good for our fitness . \\'\\n \\' What do you mean ? It will help us to relax . \\'\\n \" Do you really think so ? I don\\'t . It will just make us fat and act silly . Remember last time ? \"\\n \" I guess you are right.But what shall we do ? I don\\'t feel like sitting at home . \"\\n \\' I suggest a walk over to the gym where we can play singsong and meet some of our friends . \\'\\n \" That\\'s a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \"\\n \\' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . \\'\\n \" Good.Let \\' s go now . \" \\' All right . \\']'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def clean_and_split_dialog(raw_dialog):\n    # 1. Remove outer square brackets\n    raw_dialog = raw_dialog.strip()[1:-1]\n    \n    # 2. Replace escaped newline + quote patterns with a delimiter\n    # This helps us split utterances later\n    raw_dialog = raw_dialog.replace(\"\\\\n\", \"|\")\n    raw_dialog = raw_dialog.replace(\"\\n\", \"|\")\n    # 3. Remove leading/trailing quotes and extra whitespace\n    raw_dialog = re.sub(r\"\\\\'\", \"'\", raw_dialog)  # fix escaped apostrophes\n    raw_dialog = re.sub(r\"['\\\"]\", \"\", raw_dialog) # remove all quotes\n\n    # 4. Split on the delimiter\n    utterances = [utt.strip() for utt in raw_dialog.split(\"|\") if utt.strip()]\n    \n    return utterances\n\n# Apply to entire column\ntrain_df['utterances'] = train_df['dialog'].apply(clean_and_split_dialog)\n\n# Confirm format\nprint(\"Example split dialog:\\n\", train_df['utterances'][0])\n\n# Build input-target pairs (utterance-level)\ninput_texts = []\ntarget_texts = []\n\nfor utts in train_df['utterances']:\n    for i in range(len(utts) - 1):\n        input_texts.append(utts[i])\n        target_texts.append(utts[i + 1])\n\n# Sanity check\nprint(f\"Total Pairs: {len(input_texts)}\")\nfor i in range(3):\n    print(f\"[Input]  {input_texts[i]}\")\n    print(f\"[Target] {target_texts[i]}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:17.756710Z","iopub.execute_input":"2025-05-14T06:10:17.757261Z","iopub.status.idle":"2025-05-14T06:10:17.985026Z","shell.execute_reply.started":"2025-05-14T06:10:17.757238Z","shell.execute_reply":"2025-05-14T06:10:17.984235Z"}},"outputs":[{"name":"stdout","text":"Example split dialog:\n ['Say , Jim , how about going for a few beers after dinner ?', 'You know that is tempting but is really not good for our fitness .', 'What do you mean ? It will help us to relax .', 'Do you really think so ? I dont . It will just make us fat and act silly . Remember last time ?', 'I guess you are right.But what shall we do ? I dont feel like sitting at home .', 'I suggest a walk over to the gym where we can play singsong and meet some of our friends .', 'Thats a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them .', 'Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too .', 'Good.Let  s go now .   All right .']\nTotal Pairs: 64998\n[Input]  Say , Jim , how about going for a few beers after dinner ?\n[Target] You know that is tempting but is really not good for our fitness .\n\n[Input]  You know that is tempting but is really not good for our fitness .\n[Target] What do you mean ? It will help us to relax .\n\n[Input]  What do you mean ? It will help us to relax .\n[Target] Do you really think so ? I dont . It will just make us fat and act silly . Remember last time ?\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n# Tokenize function\ndef tokenize(sentence):\n    return sentence.lower().split()\n\n# Build vocabulary\ncounter = Counter()\nfor text in input_texts + target_texts:\n    counter.update(tokenize(text))\n\n# Special tokens\nspecial_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\nword2idx = {tok: idx for idx, tok in enumerate(special_tokens)}\nidx2word = special_tokens.copy()\n\n# Add from counter\nfor word, _ in counter.items():\n    if word not in word2idx:\n        idx = len(word2idx)\n        word2idx[word] = idx\n        idx2word.append(word)\n\nvocab_size = len(word2idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:17.985846Z","iopub.execute_input":"2025-05-14T06:10:17.986110Z","iopub.status.idle":"2025-05-14T06:10:18.415553Z","shell.execute_reply.started":"2025-05-14T06:10:17.986085Z","shell.execute_reply":"2025-05-14T06:10:18.414814Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def sentence_to_indices(sentence, word2idx):\n    tokens = tokenize(sentence)\n    return [word2idx.get('<SOS>')] + [word2idx.get(tok, word2idx['<UNK>']) for tok in tokens] + [word2idx.get('<EOS>')]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:18.416422Z","iopub.execute_input":"2025-05-14T06:10:18.416816Z","iopub.status.idle":"2025-05-14T06:10:18.422536Z","shell.execute_reply.started":"2025-05-14T06:10:18.416783Z","shell.execute_reply":"2025-05-14T06:10:18.421728Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Convert all sentences\ninput_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in input_texts]\ntarget_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in target_texts]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:18.427664Z","iopub.execute_input":"2025-05-14T06:10:18.428252Z","iopub.status.idle":"2025-05-14T06:10:20.347086Z","shell.execute_reply.started":"2025-05-14T06:10:18.428224Z","shell.execute_reply":"2025-05-14T06:10:20.345870Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\nmax_len = 20  \n\ninput_seqs_padded = pad_sequence(\n    [s[:max_len] if len(s) > max_len else torch.cat([s, torch.tensor([word2idx['<PAD>']] * (max_len - len(s)))]) for s in input_seqs],\n    batch_first=True\n)\n\ntarget_seqs_padded = pad_sequence(\n    [s[:max_len] if len(s) > max_len else torch.cat([s, torch.tensor([word2idx['<PAD>']] * (max_len - len(s)))]) for s in target_seqs],\n    batch_first=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:20.347755Z","iopub.execute_input":"2025-05-14T06:10:20.347983Z","iopub.status.idle":"2025-05-14T06:10:22.513644Z","shell.execute_reply.started":"2025-05-14T06:10:20.347967Z","shell.execute_reply":"2025-05-14T06:10:22.513081Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(f\"Vocab size: {len(word2idx)}\")\nprint(\"Sample vocab entries:\", list(word2idx.items())[:20])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:22.514454Z","iopub.execute_input":"2025-05-14T06:10:22.514669Z","iopub.status.idle":"2025-05-14T06:10:22.521408Z","shell.execute_reply.started":"2025-05-14T06:10:22.514653Z","shell.execute_reply":"2025-05-14T06:10:22.520597Z"}},"outputs":[{"name":"stdout","text":"Vocab size: 21856\nSample vocab entries: [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('say', 4), (',', 5), ('jim', 6), ('how', 7), ('about', 8), ('going', 9), ('for', 10), ('a', 11), ('few', 12), ('beers', 13), ('after', 14), ('dinner', 15), ('?', 16), ('you', 17), ('know', 18), ('that', 19)]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"sample_text = input_texts[0]\nprint(\"Original text:\", sample_text)\nprint(\"Tokens:\", tokenize(sample_text))\nprint(\"Token indices:\", sentence_to_indices(sample_text, word2idx))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:22.522236Z","iopub.execute_input":"2025-05-14T06:10:22.522484Z","iopub.status.idle":"2025-05-14T06:10:24.349905Z","shell.execute_reply.started":"2025-05-14T06:10:22.522464Z","shell.execute_reply":"2025-05-14T06:10:24.349156Z"}},"outputs":[{"name":"stdout","text":"Original text: Say , Jim , how about going for a few beers after dinner ?\nTokens: ['say', ',', 'jim', ',', 'how', 'about', 'going', 'for', 'a', 'few', 'beers', 'after', 'dinner', '?']\nToken indices: [1, 4, 5, 6, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 2]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"Input tensor shape:\", input_seqs_padded.shape)\nprint(\"Target tensor shape:\", target_seqs_padded.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:24.350602Z","iopub.execute_input":"2025-05-14T06:10:24.350890Z","iopub.status.idle":"2025-05-14T06:10:27.328146Z","shell.execute_reply.started":"2025-05-14T06:10:24.350870Z","shell.execute_reply":"2025-05-14T06:10:27.327247Z"}},"outputs":[{"name":"stdout","text":"Input tensor shape: torch.Size([64998, 20])\nTarget tensor shape: torch.Size([64998, 20])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def decode(indices, idx2word):\n    return ' '.join([idx2word[idx] for idx in indices if idx2word[idx] not in ['<PAD>', '<SOS>', '<EOS>']])\n\nprint(\"Decoded input:\", decode(input_seqs_padded[0].tolist(), idx2word))\nprint(\"Decoded target:\", decode(target_seqs_padded[0].tolist(), idx2word))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:27.329130Z","iopub.execute_input":"2025-05-14T06:10:27.329415Z","iopub.status.idle":"2025-05-14T06:10:28.344484Z","shell.execute_reply.started":"2025-05-14T06:10:27.329392Z","shell.execute_reply":"2025-05-14T06:10:28.343820Z"}},"outputs":[{"name":"stdout","text":"Decoded input: say , jim , how about going for a few beers after dinner ?\nDecoded target: you know that is tempting but is really not good for our fitness .\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"\nclass DialogDataset(Dataset):\n    def __init__(self, input_tensor, target_tensor):\n        self.inputs = input_tensor\n        self.targets = target_tensor\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.targets[idx]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.345668Z","iopub.execute_input":"2025-05-14T06:10:28.345986Z","iopub.status.idle":"2025-05-14T06:10:28.359774Z","shell.execute_reply.started":"2025-05-14T06:10:28.345968Z","shell.execute_reply":"2025-05-14T06:10:28.359215Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n\n# Initialize dataset\ndataset = DialogDataset(input_seqs_padded, target_seqs_padded)\n\n# Create DataLoader (you can adjust batch_size)\nBATCH_SIZE = 256\n\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.360517Z","iopub.execute_input":"2025-05-14T06:10:28.360728Z","iopub.status.idle":"2025-05-14T06:10:28.376601Z","shell.execute_reply.started":"2025-05-14T06:10:28.360705Z","shell.execute_reply":"2025-05-14T06:10:28.375892Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Test one batch\nfor batch in dataloader:\n    src, tgt = batch\n    print(\"Source shape:\", src.shape)  # Should be [batch_size, max_len]\n    print(\"Target shape:\", tgt.shape)\n    print(\"Sample decoded input:\", decode(src[0].tolist(), idx2word))\n    print(\"Sample decoded target:\", decode(tgt[0].tolist(), idx2word))\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.377392Z","iopub.execute_input":"2025-05-14T06:10:28.377636Z","iopub.status.idle":"2025-05-14T06:10:28.411370Z","shell.execute_reply.started":"2025-05-14T06:10:28.377614Z","shell.execute_reply":"2025-05-14T06:10:28.410821Z"}},"outputs":[{"name":"stdout","text":"Source shape: torch.Size([256, 20])\nTarget shape: torch.Size([256, 20])\nSample decoded input: excuse me , sir . i cant find my baggage . here is my claim tag .\nSample decoded target: dont worry , madam . can you make a description of your baggage ?\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"validation_df['utterances'] = validation_df['dialog'].apply(clean_and_split_dialog)\ntest_df['utterances'] = test_df['dialog'].apply(clean_and_split_dialog)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.412018Z","iopub.execute_input":"2025-05-14T06:10:28.412463Z","iopub.status.idle":"2025-05-14T06:10:28.446180Z","shell.execute_reply.started":"2025-05-14T06:10:28.412446Z","shell.execute_reply":"2025-05-14T06:10:28.445493Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def build_pairs(dialogs):\n    input_texts, target_texts = [], []\n    for utts in dialogs:\n        for i in range(len(utts) - 1):\n            input_texts.append(utts[i])\n            target_texts.append(utts[i + 1])\n    return input_texts, target_texts\n\nval_input_texts, val_target_texts = build_pairs(validation_df['utterances'])\ntest_input_texts, test_target_texts = build_pairs(test_df['utterances'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.446736Z","iopub.execute_input":"2025-05-14T06:10:28.446910Z","iopub.status.idle":"2025-05-14T06:10:28.457479Z","shell.execute_reply.started":"2025-05-14T06:10:28.446897Z","shell.execute_reply":"2025-05-14T06:10:28.456807Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"val_input_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in val_input_texts]\nval_target_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in val_target_texts]\n\ntest_input_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in test_input_texts]\ntest_target_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in test_target_texts]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.458102Z","iopub.execute_input":"2025-05-14T06:10:28.458295Z","iopub.status.idle":"2025-05-14T06:10:28.759055Z","shell.execute_reply.started":"2025-05-14T06:10:28.458281Z","shell.execute_reply":"2025-05-14T06:10:28.758387Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def pad_sequence_list(seqs, max_len):\n    return pad_sequence(\n        [s[:max_len] if len(s) > max_len else torch.cat([s, torch.tensor([word2idx['<PAD>']] * (max_len - len(s)))]) for s in seqs],\n        batch_first=True\n    )\n\nval_input_padded = pad_sequence_list(val_input_seqs, max_len)\nval_target_padded = pad_sequence_list(val_target_seqs, max_len)\n\ntest_input_padded = pad_sequence_list(test_input_seqs, max_len)\ntest_target_padded = pad_sequence_list(test_target_seqs, max_len)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:28.759795Z","iopub.execute_input":"2025-05-14T06:10:28.760015Z","iopub.status.idle":"2025-05-14T06:10:29.091543Z","shell.execute_reply.started":"2025-05-14T06:10:28.759999Z","shell.execute_reply":"2025-05-14T06:10:29.090986Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"val_dataset = DialogDataset(val_input_padded, val_target_padded)\ntest_dataset = DialogDataset(test_input_padded, test_target_padded)\n\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:29.092194Z","iopub.execute_input":"2025-05-14T06:10:29.092383Z","iopub.status.idle":"2025-05-14T06:10:29.096618Z","shell.execute_reply.started":"2025-05-14T06:10:29.092369Z","shell.execute_reply":"2025-05-14T06:10:29.095907Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Load pretrained GloVe vectors (100D)\nembedding_dim = 100\nglove_path = \"/kaggle/working/glove.6B.100d.txt\"\n\nglove = {}\nwith open(glove_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        parts = line.strip().split()\n        word = parts[0]\n        vec = np.array(parts[1:], dtype=np.float32)\n        glove[word] = vec\n\nembedding_matrix = np.zeros((len(word2idx), embedding_dim))\nfor word, idx in word2idx.items():\n    embedding_matrix[idx] = glove.get(word, np.random.normal(scale=0.6, size=embedding_dim))\n\nembedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\nembedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=word2idx['<PAD>'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:29.097259Z","iopub.execute_input":"2025-05-14T06:10:29.097419Z","iopub.status.idle":"2025-05-14T06:10:37.284608Z","shell.execute_reply.started":"2025-05-14T06:10:29.097406Z","shell.execute_reply":"2025-05-14T06:10:37.284022Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, embedding_layer, hidden_size=512, dropout=0.3, num_layers=2):\n        super().__init__()\n        self.embedding = embedding_layer\n        self.lstm = nn.LSTM(embedding_layer.embedding_dim, hidden_size, num_layers=num_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n\n    def forward(self, src, src_lengths):\n        embedded = self.embedding(src)\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=False)\n        outputs, (hidden, cell) = self.lstm(packed)\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n        return outputs, hidden, cell\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:37.285410Z","iopub.execute_input":"2025-05-14T06:10:37.285618Z","iopub.status.idle":"2025-05-14T06:10:37.290749Z","shell.execute_reply.started":"2025-05-14T06:10:37.285600Z","shell.execute_reply":"2025-05-14T06:10:37.290120Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"class BahdanauAttention(nn.Module):\n    def __init__(self, enc_hidden_size, dec_hidden_size):\n        super().__init__()\n        self.attn = nn.Linear(enc_hidden_size * 2 + dec_hidden_size, dec_hidden_size)\n        self.v = nn.Linear(dec_hidden_size, 1, bias=False)\n\n    def forward(self, decoder_hidden, encoder_outputs, mask):\n        batch_size, src_len, _ = encoder_outputs.shape\n        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n        energy = torch.tanh(self.attn(torch.cat((decoder_hidden, encoder_outputs), dim=2)))\n        scores = self.v(energy).squeeze(2)\n        scores = scores.masked_fill(mask == 0, -1e10)\n        return torch.softmax(scores, dim=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:37.291595Z","iopub.execute_input":"2025-05-14T06:10:37.292038Z","iopub.status.idle":"2025-05-14T06:10:37.309014Z","shell.execute_reply.started":"2025-05-14T06:10:37.292016Z","shell.execute_reply":"2025-05-14T06:10:37.308343Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, embedding_layer, enc_hidden_size, dec_hidden_size, attention, dropout=0.3, num_layers=1):\n        super().__init__()\n        self.embedding = embedding_layer\n        self.attention = attention\n        self.dropout = nn.Dropout(dropout)\n\n        self.lstm = nn.LSTM(embedding_layer.embedding_dim + enc_hidden_size * 2,\n                            dec_hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n        \n        self.fc_out = nn.Linear(enc_hidden_size * 2 + dec_hidden_size + embedding_layer.embedding_dim,\n                                len(word2idx))\n\n    def forward(self, input_token, hidden, cell, encoder_outputs, mask):\n        input_token = input_token.unsqueeze(1)\n        embedded = self.embedding(input_token)\n        attn_weights = self.attention(hidden[-1], encoder_outputs, mask)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n\n        lstm_input = torch.cat((embedded, attn_applied), dim=2)\n        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n\n        output = output.squeeze(1)\n        attn_applied = attn_applied.squeeze(1)\n        embedded = embedded.squeeze(1)\n\n        prediction = self.fc_out(self.dropout(torch.cat((output, attn_applied, embedded), dim=1)))\n        return prediction, hidden, cell, attn_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:37.309737Z","iopub.execute_input":"2025-05-14T06:10:37.309949Z","iopub.status.idle":"2025-05-14T06:10:37.329155Z","shell.execute_reply.started":"2025-05-14T06:10:37.309934Z","shell.execute_reply":"2025-05-14T06:10:37.328493Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, pad_idx, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.pad_idx = pad_idx\n        self.device = device\n\n        enc_hidden_size = encoder.lstm.hidden_size\n        dec_hidden_size = decoder.lstm.hidden_size\n\n        # Projects bidirectional encoder hidden/cell to decoder format\n        self.project_hidden = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n        self.project_cell = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n\n    def create_mask(self, src):\n        return (src != self.pad_idx).to(self.device)  # [B, S]\n\n    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=1.0):\n        batch_size, trg_len = trg.shape\n        vocab_size = self.decoder.fc_out.out_features\n\n        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n\n        # Encoder forward\n        encoder_outputs, enc_hidden, enc_cell = self.encoder(src, src_lengths)\n        mask = self.create_mask(src)  # [B, S]\n\n        # Process bidirectional encoder states\n        def cat_and_project(state, proj_layer):\n            # Take last layer forward and backward: [-2] and [-1]\n            cat = torch.cat((state[-2], state[-1]), dim=1)  # [B, 2*H]\n            return torch.tanh(proj_layer(cat)).unsqueeze(0)  # [1, B, H]\n\n        hidden = cat_and_project(enc_hidden, self.project_hidden)\n        cell = cat_and_project(enc_cell, self.project_cell)\n\n        # First input is <SOS>\n        input_token = trg[:, 0]\n\n        for t in range(1, trg_len):\n            output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs, mask)\n            outputs[:, t] = output\n\n            # Scheduled teacher forcing\n            top1 = output.argmax(1)\n            input_token = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:37.332116Z","iopub.execute_input":"2025-05-14T06:10:37.332316Z","iopub.status.idle":"2025-05-14T06:10:37.350255Z","shell.execute_reply.started":"2025-05-14T06:10:37.332301Z","shell.execute_reply":"2025-05-14T06:10:37.349619Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nenc_hidden_size = 512\ndec_hidden_size = 512\nattention = BahdanauAttention(enc_hidden_size, dec_hidden_size)\n\nencoder = Encoder(embedding_layer, hidden_size=enc_hidden_size)\ndecoder = Decoder(embedding_layer, enc_hidden_size, dec_hidden_size, attention)\nmodel = Seq2Seq(encoder, decoder, word2idx['<PAD>'], device).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:37.351050Z","iopub.execute_input":"2025-05-14T06:10:37.351284Z","iopub.status.idle":"2025-05-14T06:10:38.127330Z","shell.execute_reply.started":"2025-05-14T06:10:37.351270Z","shell.execute_reply":"2025-05-14T06:10:38.126804Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(label_smoothing=0.1, ignore_index=word2idx['<PAD>'])\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:38.128022Z","iopub.execute_input":"2025-05-14T06:10:38.128267Z","iopub.status.idle":"2025-05-14T06:10:42.460699Z","shell.execute_reply.started":"2025-05-14T06:10:38.128243Z","shell.execute_reply":"2025-05-14T06:10:42.460169Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(model, dataloader, optimizer, criterion, clip, tf_ratio):\n    model.train()\n    total_loss = 0\n\n    for src, trg in tqdm(dataloader, desc=\"Training\"):\n        src, trg = src.to(device), trg.to(device)\n\n        # Lengths (assuming padding is at the end)\n        src_lengths = (src != word2idx['<PAD>']).sum(dim=1)\n\n        optimizer.zero_grad()\n        output = model(src, src_lengths, trg, teacher_forcing_ratio=tf_ratio)\n\n        output = output[:, 1:].reshape(-1, output.shape[-1])\n        trg = trg[:, 1:].reshape(-1)\n\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:42.461325Z","iopub.execute_input":"2025-05-14T06:10:42.461624Z","iopub.status.idle":"2025-05-14T06:10:42.467237Z","shell.execute_reply.started":"2025-05-14T06:10:42.461608Z","shell.execute_reply":"2025-05-14T06:10:42.466339Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion):\n    model.eval()\n    total_loss = 0\n\n    with torch.no_grad():\n        for src, trg in tqdm(dataloader, desc=\"Evaluating\"):\n            src, trg = src.to(device), trg.to(device)\n            src_lengths = (src != word2idx['<PAD>']).sum(dim=1)\n\n            output = model(src, src_lengths, trg, teacher_forcing_ratio=0.0)\n            output = output[:, 1:].reshape(-1, output.shape[-1])\n            trg = trg[:, 1:].reshape(-1)\n\n            loss = criterion(output, trg)\n            total_loss += loss.item()\n\n    return total_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:42.468148Z","iopub.execute_input":"2025-05-14T06:10:42.468576Z","iopub.status.idle":"2025-05-14T06:10:42.496333Z","shell.execute_reply.started":"2025-05-14T06:10:42.468553Z","shell.execute_reply":"2025-05-14T06:10:42.495590Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"NUM_EPOCHS = 20\nclip = 1.0\nstart_tf = 1.0\ntf_decay = 0.05\nbest_val_loss = float('inf')\n\nfor epoch in range(NUM_EPOCHS):\n    tf_ratio = max(0.5, start_tf - tf_decay * epoch)\n\n    print(f\"\\nEpoch {epoch+1} | Teacher Forcing: {tf_ratio:.2f}\")\n    train_loss = train(model, dataloader, optimizer, criterion, clip, tf_ratio)\n    val_loss = evaluate(model, val_loader, criterion)\n\n    scheduler.step(val_loss)\n\n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), \"best_seq2seq_model.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:10:42.497174Z","iopub.execute_input":"2025-05-14T06:10:42.497420Z","iopub.status.idle":"2025-05-14T07:12:11.606085Z","shell.execute_reply.started":"2025-05-14T06:10:42.497399Z","shell.execute_reply":"2025-05-14T07:12:11.605481Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1 | Teacher Forcing: 1.00\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.8562 | Val Loss: 7.7112\n\nEpoch 2 | Teacher Forcing: 0.95\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.2756 | Val Loss: 7.5846\n\nEpoch 3 | Teacher Forcing: 0.90\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.1516 | Val Loss: 7.3945\n\nEpoch 4 | Teacher Forcing: 0.85\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.1160 | Val Loss: 7.2864\n\nEpoch 5 | Teacher Forcing: 0.80\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.0860 | Val Loss: 7.0044\n\nEpoch 6 | Teacher Forcing: 0.75\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:10<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.0830 | Val Loss: 6.8232\n\nEpoch 7 | Teacher Forcing: 0.70\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:10<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.0843 | Val Loss: 6.7596\n\nEpoch 8 | Teacher Forcing: 0.65\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.0504 | Val Loss: 6.5758\n\nEpoch 9 | Teacher Forcing: 0.60\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.0321 | Val Loss: 6.5727\n\nEpoch 10 | Teacher Forcing: 0.55\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.0316 | Val Loss: 6.3381\n\nEpoch 11 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.9937 | Val Loss: 6.3483\n\nEpoch 12 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:53<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.8399 | Val Loss: 6.3954\n\nEpoch 13 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:53<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:10<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.6270 | Val Loss: 6.3064\n\nEpoch 14 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:53<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.5349 | Val Loss: 6.3396\n\nEpoch 15 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.3925 | Val Loss: 6.3839\n\nEpoch 16 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.2904 | Val Loss: 6.3757\n\nEpoch 17 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.2442 | Val Loss: 6.3930\n\nEpoch 18 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.1262 | Val Loss: 6.4172\n\nEpoch 19 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\nEvaluating: 100%|██████████| 24/24 [00:10<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.1218 | Val Loss: 6.4130\n\nEpoch 20 | Teacher Forcing: 0.50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\nEvaluating: 100%|██████████| 24/24 [00:10<00:00,  2.39it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.0725 | Val Loss: 6.4302\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"test_loss = evaluate(model, test_loader, criterion)\nprint(f\"Test Loss: {test_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T07:12:11.606865Z","iopub.execute_input":"2025-05-14T07:12:11.607113Z","iopub.status.idle":"2025-05-14T07:12:20.984297Z","shell.execute_reply.started":"2025-05-14T07:12:11.607088Z","shell.execute_reply":"2025-05-14T07:12:20.983609Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 23/23 [00:09<00:00,  2.45it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 6.3844\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def generate_response_beam(model, sentence, beam_width=3, max_len=20):\n    model.eval()\n    with torch.no_grad():\n        input_tensor = torch.tensor(sentence_to_indices(sentence, word2idx)).unsqueeze(0).to(device)\n        src_lengths = torch.tensor([input_tensor.shape[1]])\n        encoder_outputs, hidden, cell = model.encoder(input_tensor, src_lengths)\n        mask = model.create_mask(input_tensor)\n\n        reduced_hidden = torch.tanh(model.project_hidden(torch.cat((hidden[-2], hidden[-1]), dim=1)))\n        reduced_cell   = torch.tanh(model.project_cell(torch.cat((cell[-2], cell[-1]), dim=1)))\n        hidden = reduced_hidden.unsqueeze(0).repeat(model.decoder.lstm.num_layers, 1, 1)\n        cell   = reduced_cell.unsqueeze(0).repeat(model.decoder.lstm.num_layers, 1, 1)\n\n        # Beam state: (tokens, score, hidden, cell)\n        beams = [([word2idx['<SOS>']], 0.0, hidden, cell)]\n        completed = []\n\n        for _ in range(max_len):\n            new_beams = []\n            for tokens, score, h, c in beams:\n                input_token = torch.tensor([tokens[-1]], device=device)\n                output, h_new, c_new, _ = model.decoder(input_token, h, c, encoder_outputs, mask)\n                log_probs = torch.log_softmax(output, dim=1).squeeze(0)\n\n                topk = torch.topk(log_probs, beam_width)\n                for idx, log_prob in zip(topk.indices.tolist(), topk.values.tolist()):\n                    new_seq = tokens + [idx]\n                    new_score = score + log_prob\n                    if idx == word2idx['<EOS>']:\n                        completed.append((new_seq, new_score))\n                    else:\n                        new_beams.append((new_seq, new_score, h_new, c_new))\n\n            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n            if not beams:\n                break\n\n        if not completed:\n            completed = beams\n\n        best_seq = sorted(completed, key=lambda x: x[1], reverse=True)[0][0]\n        return decode(best_seq[1:], idx2word)  # skip <SOS>\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T07:12:20.985025Z","iopub.execute_input":"2025-05-14T07:12:20.985271Z","iopub.status.idle":"2025-05-14T07:12:20.994173Z","shell.execute_reply.started":"2025-05-14T07:12:20.985245Z","shell.execute_reply":"2025-05-14T07:12:20.993349Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"test_sentences = [\n    \"Hi , how are you ?\",\n    \"What do you want to do tonight ?\",\n    \"Let's go to the park .\",\n    \"Are you hungry ?\"\n]\n\nfor sent in test_sentences:\n    response = generate_response_beam(model, sent)\n    print(f\"> User: {sent}\")\n    print(f\"> Bot : {response}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T07:13:51.881045Z","iopub.execute_input":"2025-05-14T07:13:51.881292Z","iopub.status.idle":"2025-05-14T07:13:52.247221Z","shell.execute_reply.started":"2025-05-14T07:13:51.881276Z","shell.execute_reply":"2025-05-14T07:13:52.246645Z"}},"outputs":[{"name":"stdout","text":"> User: Hi , how are you ?\n> Bot : fine , thank you . i am trying to get adjusted .\n\n> User: What do you want to do tonight ?\n> Bot : i have no idea what i want .\n\n> User: Let's go to the park .\n> Bot : do you want to go to the park ?\n\n> User: Are you hungry ?\n> Bot : yes , i have a lot of my friends .\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}