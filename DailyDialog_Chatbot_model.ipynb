{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:07:11.606433Z",
     "iopub.status.busy": "2025-05-14T06:07:11.606175Z",
     "iopub.status.idle": "2025-05-14T06:07:18.371444Z",
     "shell.execute_reply": "2025-05-14T06:07:18.370742Z",
     "shell.execute_reply.started": "2025-05-14T06:07:11.606412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:07:18.372971Z",
     "iopub.status.busy": "2025-05-14T06:07:18.372528Z",
     "iopub.status.idle": "2025-05-14T06:10:17.344172Z",
     "shell.execute_reply": "2025-05-14T06:10:17.343006Z",
     "shell.execute_reply.started": "2025-05-14T06:07:18.372946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-14 06:07:18--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2025-05-14 06:07:18--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2025-05-14 06:07:18--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
      "\n",
      "2025-05-14 06:09:57 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:17.345924Z",
     "iopub.status.busy": "2025-05-14T06:10:17.345596Z",
     "iopub.status.idle": "2025-05-14T06:10:17.600047Z",
     "shell.execute_reply": "2025-05-14T06:10:17.599110Z",
     "shell.execute_reply.started": "2025-05-14T06:10:17.345895Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/dailydialog-unlock-the-conversation-potential-in'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree(\"/kaggle/input/dailydialog-unlock-the-conversation-potential-in\",\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in\",dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:17.602833Z",
     "iopub.status.busy": "2025-05-14T06:10:17.602482Z",
     "iopub.status.idle": "2025-05-14T06:10:17.724312Z",
     "shell.execute_reply": "2025-05-14T06:10:17.723266Z",
     "shell.execute_reply.started": "2025-05-14T06:10:17.602803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in/train.csv\")\n",
    "validation_df = pd.read_csv(\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in/validation.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/working/dailydialog-unlock-the-conversation-potential-in/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:17.725691Z",
     "iopub.status.busy": "2025-05-14T06:10:17.725383Z",
     "iopub.status.idle": "2025-05-14T06:10:17.747756Z",
     "shell.execute_reply": "2025-05-14T06:10:17.747039Z",
     "shell.execute_reply.started": "2025-05-14T06:10:17.725666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>act</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Say , Jim , how about going for a few beers ...</td>\n",
       "      <td>[3 4 2 2 2 3 4 1 3 4]</td>\n",
       "      <td>[0 0 0 0 0 0 4 4 4 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Can you do push-ups ? '\\n \" Of course I can ...</td>\n",
       "      <td>[2 1 2 2 1 1]</td>\n",
       "      <td>[0 0 6 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Can you study with the radio on ? '\\n ' No ,...</td>\n",
       "      <td>[2 1 2 1 1]</td>\n",
       "      <td>[0 0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Are you all right ? '\\n ' I will be all righ...</td>\n",
       "      <td>[2 1 1 1]</td>\n",
       "      <td>[0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Hey John , nice skates . Are they new ? '\\n ...</td>\n",
       "      <td>[2 1 2 1 1 2 1 3 4]</td>\n",
       "      <td>[0 0 0 0 0 6 0 6 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialog                    act  \\\n",
       "0  ['Say , Jim , how about going for a few beers ...  [3 4 2 2 2 3 4 1 3 4]   \n",
       "1  ['Can you do push-ups ? '\\n \" Of course I can ...          [2 1 2 2 1 1]   \n",
       "2  ['Can you study with the radio on ? '\\n ' No ,...            [2 1 2 1 1]   \n",
       "3  ['Are you all right ? '\\n ' I will be all righ...              [2 1 1 1]   \n",
       "4  ['Hey John , nice skates . Are they new ? '\\n ...    [2 1 2 1 1 2 1 3 4]   \n",
       "\n",
       "                 emotion  \n",
       "0  [0 0 0 0 0 0 4 4 4 4]  \n",
       "1          [0 0 6 0 0 0]  \n",
       "2            [0 0 0 0 0]  \n",
       "3              [0 0 0 0]  \n",
       "4    [0 0 0 0 0 6 0 6 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:17.749009Z",
     "iopub.status.busy": "2025-05-14T06:10:17.748695Z",
     "iopub.status.idle": "2025-05-14T06:10:17.755900Z",
     "shell.execute_reply": "2025-05-14T06:10:17.755197Z",
     "shell.execute_reply.started": "2025-05-14T06:10:17.748982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'Say , Jim , how about going for a few beers after dinner ? \\'\\n \\' You know that is tempting but is really not good for our fitness . \\'\\n \\' What do you mean ? It will help us to relax . \\'\\n \" Do you really think so ? I don\\'t . It will just make us fat and act silly . Remember last time ? \"\\n \" I guess you are right.But what shall we do ? I don\\'t feel like sitting at home . \"\\n \\' I suggest a walk over to the gym where we can play singsong and meet some of our friends . \\'\\n \" That\\'s a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \"\\n \\' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . \\'\\n \" Good.Let \\' s go now . \" \\' All right . \\']'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"dialog\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:17.757261Z",
     "iopub.status.busy": "2025-05-14T06:10:17.756710Z",
     "iopub.status.idle": "2025-05-14T06:10:17.985026Z",
     "shell.execute_reply": "2025-05-14T06:10:17.984235Z",
     "shell.execute_reply.started": "2025-05-14T06:10:17.757238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example split dialog:\n",
      " ['Say , Jim , how about going for a few beers after dinner ?', 'You know that is tempting but is really not good for our fitness .', 'What do you mean ? It will help us to relax .', 'Do you really think so ? I dont . It will just make us fat and act silly . Remember last time ?', 'I guess you are right.But what shall we do ? I dont feel like sitting at home .', 'I suggest a walk over to the gym where we can play singsong and meet some of our friends .', 'Thats a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them .', 'Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too .', 'Good.Let  s go now .   All right .']\n",
      "Total Pairs: 64998\n",
      "[Input]  Say , Jim , how about going for a few beers after dinner ?\n",
      "[Target] You know that is tempting but is really not good for our fitness .\n",
      "\n",
      "[Input]  You know that is tempting but is really not good for our fitness .\n",
      "[Target] What do you mean ? It will help us to relax .\n",
      "\n",
      "[Input]  What do you mean ? It will help us to relax .\n",
      "[Target] Do you really think so ? I dont . It will just make us fat and act silly . Remember last time ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_and_split_dialog(raw_dialog):\n",
    "    raw_dialog = raw_dialog.strip()[1:-1]\n",
    "    raw_dialog = raw_dialog.replace(\"\\\\n\", \"|\")\n",
    "    raw_dialog = raw_dialog.replace(\"\\n\", \"|\")\n",
    "    raw_dialog = re.sub(r\"\\\\'\", \"'\", raw_dialog) \n",
    "    raw_dialog = re.sub(r\"['\\\"]\", \"\", raw_dialog)\n",
    "    utterances = [utt.strip() for utt in raw_dialog.split(\"|\") if utt.strip()]\n",
    "    return utterances\n",
    "\n",
    "# Apply to entire column\n",
    "train_df['utterances'] = train_df['dialog'].apply(clean_and_split_dialog)\n",
    "print(\"Example split dialog:\\n\", train_df['utterances'][0])\n",
    "\n",
    "# Build input-target pairs (utterance-level)\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "for utts in train_df['utterances']:\n",
    "    for i in range(len(utts) - 1):\n",
    "        input_texts.append(utts[i])\n",
    "        target_texts.append(utts[i + 1])\n",
    "\n",
    "# Sanity check\n",
    "print(f\"Total Pairs: {len(input_texts)}\")\n",
    "for i in range(3):\n",
    "    print(f\"[Input]  {input_texts[i]}\")\n",
    "    print(f\"[Target] {target_texts[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:17.986110Z",
     "iopub.status.busy": "2025-05-14T06:10:17.985846Z",
     "iopub.status.idle": "2025-05-14T06:10:18.415553Z",
     "shell.execute_reply": "2025-05-14T06:10:18.414814Z",
     "shell.execute_reply.started": "2025-05-14T06:10:17.986085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize function\n",
    "def tokenize(sentence):\n",
    "    return sentence.lower().split()\n",
    "\n",
    "# Build vocabulary\n",
    "counter = Counter()\n",
    "for text in input_texts + target_texts:\n",
    "    counter.update(tokenize(text))\n",
    "\n",
    "# Special tokens\n",
    "special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "word2idx = {tok: idx for idx, tok in enumerate(special_tokens)}\n",
    "idx2word = special_tokens.copy()\n",
    "\n",
    "# Add from counter\n",
    "for word, _ in counter.items():\n",
    "    if word not in word2idx:\n",
    "        idx = len(word2idx)\n",
    "        word2idx[word] = idx\n",
    "        idx2word.append(word)\n",
    "\n",
    "vocab_size = len(word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:18.416816Z",
     "iopub.status.busy": "2025-05-14T06:10:18.416422Z",
     "iopub.status.idle": "2025-05-14T06:10:18.422536Z",
     "shell.execute_reply": "2025-05-14T06:10:18.421728Z",
     "shell.execute_reply.started": "2025-05-14T06:10:18.416783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence, word2idx):\n",
    "    tokens = tokenize(sentence)\n",
    "    return [word2idx.get('<SOS>')] + [word2idx.get(tok, word2idx['<UNK>']) for tok in tokens] + [word2idx.get('<EOS>')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:18.428252Z",
     "iopub.status.busy": "2025-05-14T06:10:18.427664Z",
     "iopub.status.idle": "2025-05-14T06:10:20.347086Z",
     "shell.execute_reply": "2025-05-14T06:10:20.345870Z",
     "shell.execute_reply.started": "2025-05-14T06:10:18.428224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert all sentences\n",
    "input_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in input_texts]\n",
    "target_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in target_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:20.347983Z",
     "iopub.status.busy": "2025-05-14T06:10:20.347755Z",
     "iopub.status.idle": "2025-05-14T06:10:22.513644Z",
     "shell.execute_reply": "2025-05-14T06:10:22.513081Z",
     "shell.execute_reply.started": "2025-05-14T06:10:20.347967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "max_len = 20  \n",
    "\n",
    "input_seqs_padded = pad_sequence(\n",
    "    [s[:max_len] if len(s) > max_len else torch.cat([s, torch.tensor([word2idx['<PAD>']] * (max_len - len(s)))]) for s in input_seqs],\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "target_seqs_padded = pad_sequence(\n",
    "    [s[:max_len] if len(s) > max_len else torch.cat([s, torch.tensor([word2idx['<PAD>']] * (max_len - len(s)))]) for s in target_seqs],\n",
    "    batch_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:22.514669Z",
     "iopub.status.busy": "2025-05-14T06:10:22.514454Z",
     "iopub.status.idle": "2025-05-14T06:10:22.521408Z",
     "shell.execute_reply": "2025-05-14T06:10:22.520597Z",
     "shell.execute_reply.started": "2025-05-14T06:10:22.514653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 21856\n",
      "Sample vocab entries: [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('say', 4), (',', 5), ('jim', 6), ('how', 7), ('about', 8), ('going', 9), ('for', 10), ('a', 11), ('few', 12), ('beers', 13), ('after', 14), ('dinner', 15), ('?', 16), ('you', 17), ('know', 18), ('that', 19)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab size: {len(word2idx)}\")\n",
    "print(\"Sample vocab entries:\", list(word2idx.items())[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:22.522484Z",
     "iopub.status.busy": "2025-05-14T06:10:22.522236Z",
     "iopub.status.idle": "2025-05-14T06:10:24.349905Z",
     "shell.execute_reply": "2025-05-14T06:10:24.349156Z",
     "shell.execute_reply.started": "2025-05-14T06:10:22.522464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Say , Jim , how about going for a few beers after dinner ?\n",
      "Tokens: ['say', ',', 'jim', ',', 'how', 'about', 'going', 'for', 'a', 'few', 'beers', 'after', 'dinner', '?']\n",
      "Token indices: [1, 4, 5, 6, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 2]\n"
     ]
    }
   ],
   "source": [
    "sample_text = input_texts[0]\n",
    "print(\"Original text:\", sample_text)\n",
    "print(\"Tokens:\", tokenize(sample_text))\n",
    "print(\"Token indices:\", sentence_to_indices(sample_text, word2idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:24.350890Z",
     "iopub.status.busy": "2025-05-14T06:10:24.350602Z",
     "iopub.status.idle": "2025-05-14T06:10:27.328146Z",
     "shell.execute_reply": "2025-05-14T06:10:27.327247Z",
     "shell.execute_reply.started": "2025-05-14T06:10:24.350870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([64998, 20])\n",
      "Target tensor shape: torch.Size([64998, 20])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input tensor shape:\", input_seqs_padded.shape)\n",
    "print(\"Target tensor shape:\", target_seqs_padded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:27.329415Z",
     "iopub.status.busy": "2025-05-14T06:10:27.329130Z",
     "iopub.status.idle": "2025-05-14T06:10:28.344484Z",
     "shell.execute_reply": "2025-05-14T06:10:28.343820Z",
     "shell.execute_reply.started": "2025-05-14T06:10:27.329392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded input: say , jim , how about going for a few beers after dinner ?\n",
      "Decoded target: you know that is tempting but is really not good for our fitness .\n"
     ]
    }
   ],
   "source": [
    "def decode(indices, idx2word):\n",
    "    return ' '.join([idx2word[idx] for idx in indices if idx2word[idx] not in ['<PAD>', '<SOS>', '<EOS>']])\n",
    "\n",
    "print(\"Decoded input:\", decode(input_seqs_padded[0].tolist(), idx2word))\n",
    "print(\"Decoded target:\", decode(target_seqs_padded[0].tolist(), idx2word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.345986Z",
     "iopub.status.busy": "2025-05-14T06:10:28.345668Z",
     "iopub.status.idle": "2025-05-14T06:10:28.359774Z",
     "shell.execute_reply": "2025-05-14T06:10:28.359215Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.345968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DialogDataset(Dataset):\n",
    "    def __init__(self, input_tensor, target_tensor):\n",
    "        self.inputs = input_tensor\n",
    "        self.targets = target_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.360728Z",
     "iopub.status.busy": "2025-05-14T06:10:28.360517Z",
     "iopub.status.idle": "2025-05-14T06:10:28.376601Z",
     "shell.execute_reply": "2025-05-14T06:10:28.375892Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.360705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = DialogDataset(input_seqs_padded, target_seqs_padded)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.377636Z",
     "iopub.status.busy": "2025-05-14T06:10:28.377392Z",
     "iopub.status.idle": "2025-05-14T06:10:28.411370Z",
     "shell.execute_reply": "2025-05-14T06:10:28.410821Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.377614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape: torch.Size([256, 20])\n",
      "Target shape: torch.Size([256, 20])\n",
      "Sample decoded input: excuse me , sir . i cant find my baggage . here is my claim tag .\n",
      "Sample decoded target: dont worry , madam . can you make a description of your baggage ?\n"
     ]
    }
   ],
   "source": [
    "# Test one batch\n",
    "for batch in dataloader:\n",
    "    src, tgt = batch\n",
    "    print(\"Source shape:\", src.shape)\n",
    "    print(\"Target shape:\", tgt.shape)\n",
    "    print(\"Sample decoded input:\", decode(src[0].tolist(), idx2word))\n",
    "    print(\"Sample decoded target:\", decode(tgt[0].tolist(), idx2word))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.412463Z",
     "iopub.status.busy": "2025-05-14T06:10:28.412018Z",
     "iopub.status.idle": "2025-05-14T06:10:28.446180Z",
     "shell.execute_reply": "2025-05-14T06:10:28.445493Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.412446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_df['utterances'] = validation_df['dialog'].apply(clean_and_split_dialog)\n",
    "test_df['utterances'] = test_df['dialog'].apply(clean_and_split_dialog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.446910Z",
     "iopub.status.busy": "2025-05-14T06:10:28.446736Z",
     "iopub.status.idle": "2025-05-14T06:10:28.457479Z",
     "shell.execute_reply": "2025-05-14T06:10:28.456807Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.446897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_pairs(dialogs):\n",
    "    input_texts, target_texts = [], []\n",
    "    for utts in dialogs:\n",
    "        for i in range(len(utts) - 1):\n",
    "            input_texts.append(utts[i])\n",
    "            target_texts.append(utts[i + 1])\n",
    "    return input_texts, target_texts\n",
    "\n",
    "val_input_texts, val_target_texts = build_pairs(validation_df['utterances'])\n",
    "test_input_texts, test_target_texts = build_pairs(test_df['utterances'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.458295Z",
     "iopub.status.busy": "2025-05-14T06:10:28.458102Z",
     "iopub.status.idle": "2025-05-14T06:10:28.759055Z",
     "shell.execute_reply": "2025-05-14T06:10:28.758387Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.458281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_input_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in val_input_texts]\n",
    "val_target_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in val_target_texts]\n",
    "\n",
    "test_input_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in test_input_texts]\n",
    "test_target_seqs = [torch.tensor(sentence_to_indices(sent, word2idx)) for sent in test_target_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:28.760015Z",
     "iopub.status.busy": "2025-05-14T06:10:28.759795Z",
     "iopub.status.idle": "2025-05-14T06:10:29.091543Z",
     "shell.execute_reply": "2025-05-14T06:10:29.090986Z",
     "shell.execute_reply.started": "2025-05-14T06:10:28.759999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pad_sequence_list(seqs, max_len):\n",
    "    return pad_sequence(\n",
    "        [s[:max_len] if len(s) > max_len else torch.cat([s, torch.tensor([word2idx['<PAD>']] * (max_len - len(s)))]) for s in seqs],\n",
    "        batch_first=True\n",
    "    )\n",
    "\n",
    "val_input_padded = pad_sequence_list(val_input_seqs, max_len)\n",
    "val_target_padded = pad_sequence_list(val_target_seqs, max_len)\n",
    "\n",
    "test_input_padded = pad_sequence_list(test_input_seqs, max_len)\n",
    "test_target_padded = pad_sequence_list(test_target_seqs, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:29.092383Z",
     "iopub.status.busy": "2025-05-14T06:10:29.092194Z",
     "iopub.status.idle": "2025-05-14T06:10:29.096618Z",
     "shell.execute_reply": "2025-05-14T06:10:29.095907Z",
     "shell.execute_reply.started": "2025-05-14T06:10:29.092369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_dataset = DialogDataset(val_input_padded, val_target_padded)\n",
    "test_dataset = DialogDataset(test_input_padded, test_target_padded)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:29.097419Z",
     "iopub.status.busy": "2025-05-14T06:10:29.097259Z",
     "iopub.status.idle": "2025-05-14T06:10:37.284608Z",
     "shell.execute_reply": "2025-05-14T06:10:37.284022Z",
     "shell.execute_reply.started": "2025-05-14T06:10:29.097406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load pretrained GloVe vectors (100D)\n",
    "embedding_dim = 100\n",
    "glove_path = \"/kaggle/working/glove.6B.100d.txt\"\n",
    "\n",
    "glove = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        word = parts[0]\n",
    "        vec = np.array(parts[1:], dtype=np.float32)\n",
    "        glove[word] = vec\n",
    "\n",
    "embedding_matrix = np.zeros((len(word2idx), embedding_dim))\n",
    "for word, idx in word2idx.items():\n",
    "    embedding_matrix[idx] = glove.get(word, np.random.normal(scale=0.6, size=embedding_dim))\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=word2idx['<PAD>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:37.285618Z",
     "iopub.status.busy": "2025-05-14T06:10:37.285410Z",
     "iopub.status.idle": "2025-05-14T06:10:37.290749Z",
     "shell.execute_reply": "2025-05-14T06:10:37.290120Z",
     "shell.execute_reply.started": "2025-05-14T06:10:37.285600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_size=512, dropout=0.3, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(embedding_layer.embedding_dim, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, src, src_lengths):\n",
    "        embedded = self.embedding(src)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        return outputs, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:37.292038Z",
     "iopub.status.busy": "2025-05-14T06:10:37.291595Z",
     "iopub.status.idle": "2025-05-14T06:10:37.309014Z",
     "shell.execute_reply": "2025-05-14T06:10:37.308343Z",
     "shell.execute_reply.started": "2025-05-14T06:10:37.292016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hidden_size * 2 + dec_hidden_size, dec_hidden_size)\n",
    "        self.v = nn.Linear(dec_hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs, mask):\n",
    "        batch_size, src_len, _ = encoder_outputs.shape\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((decoder_hidden, encoder_outputs), dim=2)))\n",
    "        scores = self.v(energy).squeeze(2)\n",
    "        scores = scores.masked_fill(mask == 0, -1e10)\n",
    "        return torch.softmax(scores, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:37.309949Z",
     "iopub.status.busy": "2025-05-14T06:10:37.309737Z",
     "iopub.status.idle": "2025-05-14T06:10:37.329155Z",
     "shell.execute_reply": "2025-05-14T06:10:37.328493Z",
     "shell.execute_reply.started": "2025-05-14T06:10:37.309934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, enc_hidden_size, dec_hidden_size, attention, dropout=0.3, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.attention = attention\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_layer.embedding_dim + enc_hidden_size * 2,\n",
    "                            dec_hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(enc_hidden_size * 2 + dec_hidden_size + embedding_layer.embedding_dim,\n",
    "                                len(word2idx))\n",
    "\n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs, mask):\n",
    "        input_token = input_token.unsqueeze(1)\n",
    "        embedded = self.embedding(input_token)\n",
    "        attn_weights = self.attention(hidden[-1], encoder_outputs, mask)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "\n",
    "        lstm_input = torch.cat((embedded, attn_applied), dim=2)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "\n",
    "        output = output.squeeze(1)\n",
    "        attn_applied = attn_applied.squeeze(1)\n",
    "        embedded = embedded.squeeze(1)\n",
    "\n",
    "        prediction = self.fc_out(self.dropout(torch.cat((output, attn_applied, embedded), dim=1)))\n",
    "        return prediction, hidden, cell, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:37.332316Z",
     "iopub.status.busy": "2025-05-14T06:10:37.332116Z",
     "iopub.status.idle": "2025-05-14T06:10:37.350255Z",
     "shell.execute_reply": "2025-05-14T06:10:37.349619Z",
     "shell.execute_reply.started": "2025-05-14T06:10:37.332301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.device = device\n",
    "\n",
    "        enc_hidden_size = encoder.lstm.hidden_size\n",
    "        dec_hidden_size = decoder.lstm.hidden_size\n",
    "\n",
    " \n",
    "        self.project_hidden = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "        self.project_cell = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "\n",
    "    def create_mask(self, src):\n",
    "        return (src != self.pad_idx).to(self.device)  # [B, S]\n",
    "\n",
    "    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=1.0):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
    "\n",
    "        # Encoder forward\n",
    "        encoder_outputs, enc_hidden, enc_cell = self.encoder(src, src_lengths)\n",
    "        mask = self.create_mask(src)  # [B, S]\n",
    "\n",
    "        # Process bidirectional encoder states\n",
    "        def cat_and_project(state, proj_layer):\n",
    "            # Take last layer forward and backward: [-2] and [-1]\n",
    "            cat = torch.cat((state[-2], state[-1]), dim=1)  # [B, 2*H]\n",
    "            return torch.tanh(proj_layer(cat)).unsqueeze(0)  # [1, B, H]\n",
    "\n",
    "        hidden = cat_and_project(enc_hidden, self.project_hidden)\n",
    "        cell = cat_and_project(enc_cell, self.project_cell)\n",
    "\n",
    "        # First input is <SOS>\n",
    "        input_token = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs, mask)\n",
    "            outputs[:, t] = output\n",
    "\n",
    "            # Scheduled teacher forcing\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:37.351284Z",
     "iopub.status.busy": "2025-05-14T06:10:37.351050Z",
     "iopub.status.idle": "2025-05-14T06:10:38.127330Z",
     "shell.execute_reply": "2025-05-14T06:10:38.126804Z",
     "shell.execute_reply.started": "2025-05-14T06:10:37.351270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "enc_hidden_size = 512\n",
    "dec_hidden_size = 512\n",
    "attention = BahdanauAttention(enc_hidden_size, dec_hidden_size)\n",
    "\n",
    "encoder = Encoder(embedding_layer, hidden_size=enc_hidden_size)\n",
    "decoder = Decoder(embedding_layer, enc_hidden_size, dec_hidden_size, attention)\n",
    "model = Seq2Seq(encoder, decoder, word2idx['<PAD>'], device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:38.128267Z",
     "iopub.status.busy": "2025-05-14T06:10:38.128022Z",
     "iopub.status.idle": "2025-05-14T06:10:42.460699Z",
     "shell.execute_reply": "2025-05-14T06:10:42.460169Z",
     "shell.execute_reply.started": "2025-05-14T06:10:38.128243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1, ignore_index=word2idx['<PAD>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:42.461624Z",
     "iopub.status.busy": "2025-05-14T06:10:42.461325Z",
     "iopub.status.idle": "2025-05-14T06:10:42.467237Z",
     "shell.execute_reply": "2025-05-14T06:10:42.466339Z",
     "shell.execute_reply.started": "2025-05-14T06:10:42.461608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, dataloader, optimizer, criterion, clip, tf_ratio):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, trg in tqdm(dataloader, desc=\"Training\"):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        # Lengths (assuming padding is at the end)\n",
    "        src_lengths = (src != word2idx['<PAD>']).sum(dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lengths, trg, teacher_forcing_ratio=tf_ratio)\n",
    "\n",
    "        output = output[:, 1:].reshape(-1, output.shape[-1])\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:42.468576Z",
     "iopub.status.busy": "2025-05-14T06:10:42.468148Z",
     "iopub.status.idle": "2025-05-14T06:10:42.496333Z",
     "shell.execute_reply": "2025-05-14T06:10:42.495590Z",
     "shell.execute_reply.started": "2025-05-14T06:10:42.468553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            src_lengths = (src != word2idx['<PAD>']).sum(dim=1)\n",
    "\n",
    "            output = model(src, src_lengths, trg, teacher_forcing_ratio=0.0)\n",
    "            output = output[:, 1:].reshape(-1, output.shape[-1])\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:10:42.497420Z",
     "iopub.status.busy": "2025-05-14T06:10:42.497174Z",
     "iopub.status.idle": "2025-05-14T07:12:11.606085Z",
     "shell.execute_reply": "2025-05-14T07:12:11.605481Z",
     "shell.execute_reply.started": "2025-05-14T06:10:42.497399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | Teacher Forcing: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.8562 | Val Loss: 7.7112\n",
      "\n",
      "Epoch 2 | Teacher Forcing: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.2756 | Val Loss: 7.5846\n",
      "\n",
      "Epoch 3 | Teacher Forcing: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.1516 | Val Loss: 7.3945\n",
      "\n",
      "Epoch 4 | Teacher Forcing: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.1160 | Val Loss: 7.2864\n",
      "\n",
      "Epoch 5 | Teacher Forcing: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.0860 | Val Loss: 7.0044\n",
      "\n",
      "Epoch 6 | Teacher Forcing: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.0830 | Val Loss: 6.8232\n",
      "\n",
      "Epoch 7 | Teacher Forcing: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.0843 | Val Loss: 6.7596\n",
      "\n",
      "Epoch 8 | Teacher Forcing: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.0504 | Val Loss: 6.5758\n",
      "\n",
      "Epoch 9 | Teacher Forcing: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.0321 | Val Loss: 6.5727\n",
      "\n",
      "Epoch 10 | Teacher Forcing: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.0316 | Val Loss: 6.3381\n",
      "\n",
      "Epoch 11 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.9937 | Val Loss: 6.3483\n",
      "\n",
      "Epoch 12 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:53<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.8399 | Val Loss: 6.3954\n",
      "\n",
      "Epoch 13 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:53<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.6270 | Val Loss: 6.3064\n",
      "\n",
      "Epoch 14 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:53<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.5349 | Val Loss: 6.3396\n",
      "\n",
      "Epoch 15 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.3925 | Val Loss: 6.3839\n",
      "\n",
      "Epoch 16 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.2904 | Val Loss: 6.3757\n",
      "\n",
      "Epoch 17 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.2442 | Val Loss: 6.3930\n",
      "\n",
      "Epoch 18 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.1262 | Val Loss: 6.4172\n",
      "\n",
      "Epoch 19 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.45it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.1218 | Val Loss: 6.4130\n",
      "\n",
      "Epoch 20 | Teacher Forcing: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 254/254 [02:54<00:00,  1.46it/s]\n",
      "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.0725 | Val Loss: 6.4302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "clip = 1.0\n",
    "start_tf = 1.0\n",
    "tf_decay = 0.05\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    tf_ratio = max(0.5, start_tf - tf_decay * epoch)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} | Teacher Forcing: {tf_ratio:.2f}\")\n",
    "    train_loss = train(model, dataloader, optimizer, criterion, clip, tf_ratio)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_seq2seq_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T07:12:11.607113Z",
     "iopub.status.busy": "2025-05-14T07:12:11.606865Z",
     "iopub.status.idle": "2025-05-14T07:12:20.984297Z",
     "shell.execute_reply": "2025-05-14T07:12:20.983609Z",
     "shell.execute_reply.started": "2025-05-14T07:12:11.607088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 23/23 [00:09<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T07:12:20.985271Z",
     "iopub.status.busy": "2025-05-14T07:12:20.985025Z",
     "iopub.status.idle": "2025-05-14T07:12:20.994173Z",
     "shell.execute_reply": "2025-05-14T07:12:20.993349Z",
     "shell.execute_reply.started": "2025-05-14T07:12:20.985245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response_beam(model, sentence, beam_width=3, max_len=20):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(sentence_to_indices(sentence, word2idx)).unsqueeze(0).to(device)\n",
    "        src_lengths = torch.tensor([input_tensor.shape[1]])\n",
    "        encoder_outputs, hidden, cell = model.encoder(input_tensor, src_lengths)\n",
    "        mask = model.create_mask(input_tensor)\n",
    "\n",
    "        reduced_hidden = torch.tanh(model.project_hidden(torch.cat((hidden[-2], hidden[-1]), dim=1)))\n",
    "        reduced_cell   = torch.tanh(model.project_cell(torch.cat((cell[-2], cell[-1]), dim=1)))\n",
    "        hidden = reduced_hidden.unsqueeze(0).repeat(model.decoder.lstm.num_layers, 1, 1)\n",
    "        cell   = reduced_cell.unsqueeze(0).repeat(model.decoder.lstm.num_layers, 1, 1)\n",
    "\n",
    "        # Beam state: (tokens, score, hidden, cell)\n",
    "        beams = [([word2idx['<SOS>']], 0.0, hidden, cell)]\n",
    "        completed = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            new_beams = []\n",
    "            for tokens, score, h, c in beams:\n",
    "                input_token = torch.tensor([tokens[-1]], device=device)\n",
    "                output, h_new, c_new, _ = model.decoder(input_token, h, c, encoder_outputs, mask)\n",
    "                log_probs = torch.log_softmax(output, dim=1).squeeze(0)\n",
    "\n",
    "                topk = torch.topk(log_probs, beam_width)\n",
    "                for idx, log_prob in zip(topk.indices.tolist(), topk.values.tolist()):\n",
    "                    new_seq = tokens + [idx]\n",
    "                    new_score = score + log_prob\n",
    "                    if idx == word2idx['<EOS>']:\n",
    "                        completed.append((new_seq, new_score))\n",
    "                    else:\n",
    "                        new_beams.append((new_seq, new_score, h_new, c_new))\n",
    "\n",
    "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "            if not beams:\n",
    "                break\n",
    "\n",
    "        if not completed:\n",
    "            completed = beams\n",
    "\n",
    "        best_seq = sorted(completed, key=lambda x: x[1], reverse=True)[0][0]\n",
    "        return decode(best_seq[1:], idx2word)  # skip <SOS>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T07:13:51.881292Z",
     "iopub.status.busy": "2025-05-14T07:13:51.881045Z",
     "iopub.status.idle": "2025-05-14T07:13:52.247221Z",
     "shell.execute_reply": "2025-05-14T07:13:52.246645Z",
     "shell.execute_reply.started": "2025-05-14T07:13:51.881276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> User: Hi , how are you ?\n",
      "> Bot : fine , thank you . i am trying to get adjusted .\n",
      "\n",
      "> User: What do you want to do tonight ?\n",
      "> Bot : i have no idea what i want .\n",
      "\n",
      "> User: Let's go to the park .\n",
      "> Bot : do you want to go to the park ?\n",
      "\n",
      "> User: Are you hungry ?\n",
      "> Bot : yes , i have a lot of my friends .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"Hi , how are you ?\",\n",
    "    \"What do you want to do tonight ?\",\n",
    "    \"Let's go to the park .\",\n",
    "    \"Are you hungry ?\"\n",
    "]\n",
    "\n",
    "for sent in test_sentences:\n",
    "    response = generate_response_beam(model, sent)\n",
    "    print(f\"> User: {sent}\")\n",
    "    print(f\"> Bot : {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- as shown the resualts are not human like but demonstrate the model's ability to learn and generate coherent responses.\n",
    "- this is a proof of concept, and the model can be further improved and fine-tuned to improve its performance on specific tasks.\n",
    "- the model's poor preformance an be atributed to the limited training data and the simplicity of the model architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2688897,
     "sourceId": 4619727,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
